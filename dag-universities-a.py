from datetime import timedelta, datetime
from airflow import DAG
from airflow.operators.dummy import DummyOperator

default_args = {
    'retries': 1,
    'retry_delay': timedelta(minutes=5)
}

# Instanciamos dag
with DAG(
    'dag_universities_a',
    default_args=default_args,
    description='DAG para la Universidad De Flores y Universidad Nacional De Villa MarÃ­a. Documenta los operators que se utilizan a futuro, teniendo en cuenta que se va a hacer una consulta SQL, se van a procesar los datos con pandas y se van a cargar los datos en S3',
    schedule_interval=timedelta(hours=1),
    start_date=datetime(2022, 1, 26),
) as dag:
    query_sql = DummyOperator(task_id='query_sql') # Consulta SQL
    pandas_process = DummyOperator(task_id='pandas_process') # Procesar datos con pandas
    load_S3 = DummyOperator(task_id='load_S3') # Carga de datos en S3

    query_sql >> pandas_process >> load_S3
